{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import wandb\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nZDxUcVde6J_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7P1KcU6me3yv"
      },
      "outputs": [],
      "source": [
        "# Building CNN from scratch\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_channels=3,\n",
        "                 num_classes=10,\n",
        "                 conv_filters=[32, 64, 128, 256, 512],\n",
        "                 kernel_size=3,\n",
        "                 activation_fn=nn.ReLU,\n",
        "                 dense_neurons=256,\n",
        "                 input_image_size=(224, 224)):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = input_channels\n",
        "\n",
        "        for out_channels in conv_filters:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2)\n",
        "            self.conv_layers.append(conv)\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.activation_fn = activation_fn()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.flattened_size = None\n",
        "        self.dense = None\n",
        "        self.output = None\n",
        "\n",
        "        self.dense_neurons = dense_neurons\n",
        "        self.num_classes = num_classes\n",
        "        self.input_image_size = input_image_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, conv in enumerate(self.conv_layers):\n",
        "            x = conv(x)\n",
        "            x = self.activation_fn(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.activation_fn(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        if self.flattened_size is None:\n",
        "            self.flattened_size = x.view(x.size(0), -1).shape[1]\n",
        "            self.dense = nn.Linear(self.flattened_size, self.dense_neurons).to(x.device)\n",
        "            self.output = nn.Linear(self.dense_neurons, self.num_classes).to(x.device)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dense(x)\n",
        "        x = self.activation_fn(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "    def calculate_total_parameters_and_computations(self):\n",
        "        H, W = self.input_image_size\n",
        "        C = 3\n",
        "        total_params = 0\n",
        "        total_ops = 0\n",
        "\n",
        "        print(\"Calculating total parameters and computations:\")\n",
        "\n",
        "        for i, conv in enumerate(self.conv_layers):\n",
        "            out_channels = conv.out_channels\n",
        "            k = conv.kernel_size[0]\n",
        "            params_per_filter = k * k * C + 1\n",
        "            layer_params = out_channels * params_per_filter\n",
        "            total_params += layer_params\n",
        "\n",
        "            ops_per_pixel = k * k * C\n",
        "            H_out, W_out = H // 2, W // 2\n",
        "            layer_ops = H_out * W_out * out_channels * ops_per_pixel\n",
        "            total_ops += layer_ops\n",
        "\n",
        "            print(f\"Layer {i+1}: Params={layer_params}, Ops={layer_ops}\")\n",
        "\n",
        "            H, W = H_out, W_out\n",
        "            C = out_channels\n",
        "\n",
        "        H, W = H // 2, W // 2\n",
        "\n",
        "        f = C * H * W\n",
        "        dense_params = f * self.dense_neurons + self.dense_neurons\n",
        "        dense_ops = f * self.dense_neurons\n",
        "\n",
        "        output_params = self.dense_neurons * self.num_classes + self.num_classes\n",
        "        output_ops = self.dense_neurons * self.num_classes\n",
        "\n",
        "        print(f\"Dense Layer: Params={dense_params}, Ops={dense_ops}\")\n",
        "        print(f\"Output Layer: Params={output_params}, Ops={output_ops}\")\n",
        "\n",
        "        total_params += dense_params + output_params\n",
        "        total_ops += dense_ops + output_ops\n",
        "\n",
        "        print(f\"Total Parameters: {total_params}, Total Operations: {total_ops}\")\n",
        "        return total_params, total_ops\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data and split\n",
        "def load_data(data_dir, batch_size=64, augment=True):\n",
        "    print(\"Preparing data with augmentation:\" if augment else \"Preparing data without augmentation\")\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224) if augment else transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip() if augment else transforms.Lambda(lambda x: x),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    train_data = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=transform_train)\n",
        "    val_size = int(0.2 * len(train_data))\n",
        "    train_size = len(train_data) - val_size\n",
        "    train_set, val_set = random_split(train_data, [train_size, val_size])\n",
        "\n",
        "    test_set = datasets.ImageFolder(root=f\"{data_dir}/val\", transform=transform_test)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "    print(f\"Train size: {train_size}, Val size: {val_size}, Test size: {len(test_set)}\")\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "Z-USX_DHfBgp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save & load checkpoints\n",
        "def save_checkpoint(model, optimizer, epoch, filename=\"checkpoint.pth\"):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"Checkpoint saved at epoch {epoch}.\")\n",
        "\n",
        "\n",
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    \"\"\"\n",
        "    Load model and optimizer state from checkpoint.\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    return checkpoint.get('epoch', 0)\n"
      ],
      "metadata": {
        "id": "LeN5WfBnkiPK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Validation\n",
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=\"Validating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    return val_acc\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10, checkpoint_path=None):\n",
        "    model.to(device)\n",
        "\n",
        "    # Create checkpoint path using wandb run ID\n",
        "    run_id = wandb.run.id if wandb.run else \"default\"\n",
        "    checkpoint_dir = \"checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    checkpoint_path = checkpoint_path or os.path.join(checkpoint_dir, f\"ckpt_{run_id}.pth\")\n",
        "\n",
        "    # Try loading from checkpoint\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            start_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "            print(f\"✅ Loaded checkpoint from '{checkpoint_path}', resuming at epoch {start_epoch}.\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"⚠️  Skipping checkpoint load due to mismatch:\\n{e}\")\n",
        "            start_epoch = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}:\")\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        val_acc = validate_model(model, val_loader, device)\n",
        "\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": total_loss / total,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "\n",
        "        print(f\"✅ Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        # Save checkpoint at end of epoch\n",
        "        save_checkpoint(model, optimizer, epoch + 1, checkpoint_path)\n",
        "        print(f\"💾 Checkpoint saved to {checkpoint_path}\")\n"
      ],
      "metadata": {
        "id": "QPRta5ZPqWWM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sweep_config():\n",
        "    sweep_config = {\n",
        "        'method': 'bayes',\n",
        "        'metric': {\n",
        "            'name': 'val_acc',\n",
        "            'goal': 'maximize'\n",
        "        },\n",
        "        'parameters': {\n",
        "            #'conv_filters': {\n",
        "            #    'values': [[32, 64, 128, 256, 512], [32]*5, [64]*5, [128, 64, 32, 16, 8]]\n",
        "            #},\n",
        "            'conv_filters': {\n",
        "                'values': [[32, 64, 128, 256, 512], [128, 64, 32, 16, 8]]\n",
        "            },\n",
        "            'activation_fn': {\n",
        "                #'values': ['ReLU', 'GELU', 'SiLU', 'Mish']\n",
        "                'values': ['ReLU', 'GELU', 'SiLU', 'Mish', 'LeakyReLU']\n",
        "            },\n",
        "            'augment': {\n",
        "                'values': [True, False]\n",
        "            },\n",
        "            'batch_norm': {\n",
        "                'values': [True, False]\n",
        "            },\n",
        "            'dropout': {\n",
        "                'values': [0.2, 0.3]\n",
        "            },\n",
        "            'dense_neurons': {\n",
        "                'values': [128, 256, 512]\n",
        "            },\n",
        "            'learning_rate': {\n",
        "                'values': [0.001, 0.0005]\n",
        "            },\n",
        "            'num_epochs': {\n",
        "                'values': [3, 5, 7]\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'values': [16, 32, 64]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    return sweep_config\n",
        "\n",
        "\n",
        "def save_sweep_hyperparameters_to_file(config, filename=\"sweep_hyperparameters.json\"):\n",
        "    \"\"\"\n",
        "    Save the hyperparameters and their values to a file after each sweep run.\n",
        "    This function will append new sweeps to the existing file without overwriting.\n",
        "    \"\"\"\n",
        "    sweep_params = {\n",
        "        \"conv_filters\": config['conv_filters'],\n",
        "        \"activation_fn\": config['activation_fn'],\n",
        "        \"augment\": config['augment'],\n",
        "        \"batch_norm\": config['batch_norm'],\n",
        "        \"dropout\": config['dropout'],\n",
        "        \"dense_neurons\": config['dense_neurons'],\n",
        "        \"learning_rate\": config['learning_rate'],\n",
        "        \"num_epochs\": config['num_epochs'],\n",
        "        \"batch_size\": config['batch_size'],\n",
        "        \"sweep_run_id\": wandb.run.id  # Add a unique sweep run ID to each entry\n",
        "    }\n",
        "\n",
        "    # Check if file exists, if so, append to it; if not, create a new file\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            all_sweeps = json.load(f)\n",
        "    else:\n",
        "        all_sweeps = []\n",
        "\n",
        "    all_sweeps.append(sweep_params)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(all_sweeps, f, indent=4)\n",
        "    print(f\"Hyperparameters saved to {filename}\")\n",
        "\n",
        "\n",
        "def run_sweep(train_loader, val_loader, test_loader):\n",
        "    wandb.init(\n",
        "        project=\"DA6401_DL_ASSIGNMENT_02_PART_A\",\n",
        "        entity=\"subikksha-indian-institute-of-technology-madras\"\n",
        "    )\n",
        "\n",
        "    config = wandb.config\n",
        "\n",
        "    run_name = f\"filters_{'_'.join(map(str, config.conv_filters))}_act_{config.activation_fn}_drop_{config.dropout}_lr_{config.learning_rate}_bn_{config.batch_norm}\"\n",
        "    wandb.run.name = run_name\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    save_sweep_hyperparameters_to_file(config)\n",
        "\n",
        "    model = CNN(\n",
        "        conv_filters=config.conv_filters,\n",
        "        activation_fn=getattr(nn, config.activation_fn),\n",
        "        dense_neurons=config.dense_neurons\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, epochs=config.num_epochs, device=device)\n",
        "\n",
        "    final_val_acc = validate_model(model, val_loader, device=device)\n",
        "    wandb.log({\"final_val_acc\": final_val_acc})\n",
        "\n",
        "    wandb.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhdxMaKirzmX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"7ea09f7c4132c66373b03708516876ea8ecc67cc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIh0uuZmsRK4",
        "outputId": "41e83b42-113d-480a-a8d2-e2522a52d545"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msubikksha\u001b[0m (\u001b[33msubikksha-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = \"DA6401_DL_ASSIGNMENT_02_PART_A\"\n",
        "ENTITY = \"subikksha-indian-institute-of-technology-madras\""
      ],
      "metadata": {
        "id": "OF_ZD_eFsDul"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "SAMPLE_SIZE = 0.30\n",
        "os.makedirs('/content/drive/MyDrive/checkpoints', exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS6AWsqktTQC",
        "outputId": "616288d5-2b21-4818-eef9-2f81a0e2588f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/DL_Data/nature_12K/inaturalist_12K'\n",
        "train_loader, val_loader, test_loader = load_data(data_dir, batch_size=64, augment=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK-X5CLiMkl1",
        "outputId": "69c7ab09-8594-4f9f-c9ec-b3ffcaa68fd9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data with augmentation:\n",
            "Train size: 8008, Val size: 2001, Test size: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sweep_wrapper():\n",
        "    run_sweep(train_loader, val_loader, test_loader)\n"
      ],
      "metadata": {
        "id": "3bfOlJdIMUBz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sweep configuration\n",
        "sweep_config = get_sweep_config()\n",
        "\n",
        "# Start sweep\n",
        "#sweep_id = wandb.sweep(sweep_config, project=PROJECT_NAME, entity=ENTITY)\n",
        "sweep_id = \"subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/vnqurpmm\"\n",
        "wandb.agent(sweep_id, function=sweep_wrapper, count=2)  # Number of sweep trials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TmfVOxsasBQT",
        "outputId": "655965e9-0b60-4bc3-bdb5-e3fee11a843a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dcqstzti with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: ReLU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128, 256, 512]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'DA6401_DL_ASSIGNMENT_02_PART_A' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring entity 'subikksha-indian-institute-of-technology-madras' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250419_070234-dcqstzti</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/dcqstzti' target=\"_blank\">glorious-sweep-11</a></strong> to <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/dcqstzti' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/dcqstzti</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Hyperparameters saved to sweep_hyperparameters.json\n",
            "\n",
            "Epoch 1/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 126/126 [29:06<00:00, 13.86s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:38<00:00,  6.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 12.89% | Val Acc: 16.39%\n",
            "Checkpoint saved at epoch 1.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_dcqstzti.pth\n",
            "\n",
            "Epoch 2/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|██████████| 126/126 [29:17<00:00, 13.95s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:26<00:00,  6.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 18.89% | Val Acc: 17.24%\n",
            "Checkpoint saved at epoch 2.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_dcqstzti.pth\n",
            "\n",
            "Epoch 3/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|██████████| 126/126 [29:19<00:00, 13.97s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:22<00:00,  6.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 20.39% | Val Acc: 21.49%\n",
            "Checkpoint saved at epoch 3.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_dcqstzti.pth\n",
            "\n",
            "Epoch 4/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|██████████| 126/126 [28:56<00:00, 13.78s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:23<00:00,  6.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 22.13% | Val Acc: 22.19%\n",
            "Checkpoint saved at epoch 4.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_dcqstzti.pth\n",
            "\n",
            "Epoch 5/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|██████████| 126/126 [29:29<00:00, 14.04s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:35<00:00,  6.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 22.00% | Val Acc: 22.19%\n",
            "Checkpoint saved at epoch 5.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_dcqstzti.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 32/32 [03:23<00:00,  6.36s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>final_val_acc</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>train_loss</td><td>█▄▃▁▁</td></tr><tr><td>val_acc</td><td>▁▂▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>final_val_acc</td><td>23.63818</td></tr><tr><td>train_acc</td><td>22.003</td></tr><tr><td>train_loss</td><td>2.11727</td></tr><tr><td>val_acc</td><td>22.18891</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">filters_32_64_128_256_512_act_ReLU_drop_0.3_lr_0.0005_bn_True</strong> at: <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/dcqstzti' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/dcqstzti</a><br> View project at: <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250419_070234-dcqstzti/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cb3pe6uw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128, 256, 512]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'DA6401_DL_ASSIGNMENT_02_PART_A' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring entity 'subikksha-indian-institute-of-technology-madras' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250419_094942-cb3pe6uw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/cb3pe6uw' target=\"_blank\">sleek-sweep-12</a></strong> to <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/sweeps/vnqurpmm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/cb3pe6uw' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/cb3pe6uw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Hyperparameters saved to sweep_hyperparameters.json\n",
            "\n",
            "Epoch 1/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 126/126 [31:25<00:00, 14.97s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:43<00:00,  6.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 15.16% | Val Acc: 17.99%\n",
            "Checkpoint saved at epoch 1.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_cb3pe6uw.pth\n",
            "\n",
            "Epoch 2/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2: 100%|██████████| 126/126 [31:28<00:00, 14.98s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:45<00:00,  7.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 20.79% | Val Acc: 22.04%\n",
            "Checkpoint saved at epoch 2.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_cb3pe6uw.pth\n",
            "\n",
            "Epoch 3/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3: 100%|██████████| 126/126 [30:38<00:00, 14.59s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:53<00:00,  7.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 25.20% | Val Acc: 25.59%\n",
            "Checkpoint saved at epoch 3.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_cb3pe6uw.pth\n",
            "\n",
            "Epoch 4/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4: 100%|██████████| 126/126 [31:28<00:00, 14.99s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:58<00:00,  7.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 26.94% | Val Acc: 27.59%\n",
            "Checkpoint saved at epoch 4.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_cb3pe6uw.pth\n",
            "\n",
            "Epoch 5/5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5: 100%|██████████| 126/126 [31:34<00:00, 15.03s/it]\n",
            "Validating: 100%|██████████| 32/32 [03:45<00:00,  7.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Acc: 29.18% | Val Acc: 28.69%\n",
            "Checkpoint saved at epoch 5.\n",
            "💾 Checkpoint saved to checkpoints/ckpt_cb3pe6uw.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 32/32 [03:57<00:00,  7.43s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>final_val_acc</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▄▆▇█</td></tr><tr><td>train_loss</td><td>█▆▄▂▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>final_val_acc</td><td>28.83558</td></tr><tr><td>train_acc</td><td>29.18332</td></tr><tr><td>train_loss</td><td>1.98869</td></tr><tr><td>val_acc</td><td>28.68566</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">filters_32_64_128_256_512_act_GELU_drop_0.3_lr_0.0005_bn_False</strong> at: <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/cb3pe6uw' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A/runs/cb3pe6uw</a><br> View project at: <a href='https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A' target=\"_blank\">https://wandb.ai/subikksha-indian-institute-of-technology-madras/DA6401_DL_ASSIGNMENT_02_PART_A</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250419_094942-cb3pe6uw/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sorted_sweep_results(sweep_id, project, entity, metric='final_val_acc', descending=True):\n",
        "    # Login to WandB if not already\n",
        "    wandb.login()\n",
        "\n",
        "    api = wandb.Api()\n",
        "    sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
        "\n",
        "    records = []\n",
        "    for run in sweep.runs:\n",
        "        row = {\n",
        "            \"run_id\": run.id,\n",
        "            \"name\": run.name,\n",
        "            \"final_val_acc\": run.summary.get(\"final_val_acc\", None)\n",
        "        }\n",
        "        # Add all config parameters\n",
        "        for key, value in run.config.items():\n",
        "            if not key.startswith('_'):\n",
        "                row[key] = value\n",
        "        records.append(row)\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "    df_sorted = df.sort_values(by=metric, ascending=not descending).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nTop Hyperparameter Configurations by\", metric)\n",
        "    display(df_sorted)\n",
        "    #return df_sorted\n",
        "\n",
        "get_sorted_sweep_results(\n",
        "    sweep_id=\"vnqurpmm\",\n",
        "    project=\"DA6401_DL_ASSIGNMENT_02_PART_A\",\n",
        "    entity=\"subikksha-indian-institute-of-technology-madras\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "5Mph8On3Hzjf",
        "outputId": "85d75bb9-b3c7-4fe8-d52c-776d500ea5a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Hyperparameter Configurations by final_val_acc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      run_id                                               name  \\\n",
              "0   cb3pe6uw  filters_32_64_128_256_512_act_GELU_drop_0.3_lr...   \n",
              "1   bcxxik6e  filters_32_64_128_256_512_act_ReLU_drop_0.3_lr...   \n",
              "2   dcqstzti  filters_32_64_128_256_512_act_ReLU_drop_0.3_lr...   \n",
              "3   3zjvp08t  filters_32_32_32_32_32_act_GELU_drop_0.3_lr_0....   \n",
              "4   9xj83q16  filters_64_64_64_64_64_act_Mish_drop_0.3_lr_0....   \n",
              "5   ae7rkta1  filters_64_64_64_64_64_act_ReLU_drop_0.3_lr_0....   \n",
              "6   85rvt8bv  filters_32_32_32_32_32_act_GELU_drop_0.3_lr_0....   \n",
              "7   nwjsp1rh  filters_128_64_32_16_8_act_SiLU_drop_0.2_lr_0....   \n",
              "8   2grudf0s  filters_32_64_128_256_512_act_ReLU_drop_0.3_lr...   \n",
              "9   d7lyctax  filters_32_32_32_32_32_act_SiLU_drop_0.3_lr_0....   \n",
              "10  aczycbfv  filters_32_32_32_32_32_act_ReLU_drop_0.2_lr_0....   \n",
              "11  rsglf1xw  filters_128_64_32_16_8_act_SiLU_drop_0.2_lr_0....   \n",
              "\n",
              "    final_val_acc  augment  dropout  batch_norm  batch_size  num_epochs  \\\n",
              "0       28.835582     True      0.3       False          16           5   \n",
              "1       23.788106    False      0.3        True          16           5   \n",
              "2       23.638181     True      0.3        True          16           5   \n",
              "3       23.588206     True      0.3        True          64           7   \n",
              "4       22.138931    False      0.3       False          32           3   \n",
              "5       21.189405    False      0.3       False          64           5   \n",
              "6       20.289855     True      0.3       False          32           5   \n",
              "7       19.740130    False      0.2       False          16           7   \n",
              "8       19.590205     True      0.3        True          16           3   \n",
              "9       18.490755     True      0.3        True          16           5   \n",
              "10      17.391304    False      0.2        True          16           3   \n",
              "11      17.341329    False      0.2       False          16           3   \n",
              "\n",
              "               conv_filters activation_fn  dense_neurons  learning_rate  \n",
              "0   [32, 64, 128, 256, 512]          GELU            128         0.0005  \n",
              "1   [32, 64, 128, 256, 512]          ReLU            128         0.0005  \n",
              "2   [32, 64, 128, 256, 512]          ReLU            256         0.0005  \n",
              "3      [32, 32, 32, 32, 32]          GELU            128         0.0010  \n",
              "4      [64, 64, 64, 64, 64]          Mish            512         0.0010  \n",
              "5      [64, 64, 64, 64, 64]          ReLU            128         0.0005  \n",
              "6      [32, 32, 32, 32, 32]          GELU            256         0.0010  \n",
              "7      [128, 64, 32, 16, 8]          SiLU            128         0.0005  \n",
              "8   [32, 64, 128, 256, 512]          ReLU            128         0.0010  \n",
              "9      [32, 32, 32, 32, 32]          SiLU            256         0.0010  \n",
              "10     [32, 32, 32, 32, 32]          ReLU            256         0.0005  \n",
              "11     [128, 64, 32, 16, 8]          SiLU            512         0.0010  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a886b791-60a7-4d2c-8ec7-a3e2fe104792\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>name</th>\n",
              "      <th>final_val_acc</th>\n",
              "      <th>augment</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_norm</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>conv_filters</th>\n",
              "      <th>activation_fn</th>\n",
              "      <th>dense_neurons</th>\n",
              "      <th>learning_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb3pe6uw</td>\n",
              "      <td>filters_32_64_128_256_512_act_GELU_drop_0.3_lr...</td>\n",
              "      <td>28.835582</td>\n",
              "      <td>True</td>\n",
              "      <td>0.3</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>[32, 64, 128, 256, 512]</td>\n",
              "      <td>GELU</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bcxxik6e</td>\n",
              "      <td>filters_32_64_128_256_512_act_ReLU_drop_0.3_lr...</td>\n",
              "      <td>23.788106</td>\n",
              "      <td>False</td>\n",
              "      <td>0.3</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>[32, 64, 128, 256, 512]</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dcqstzti</td>\n",
              "      <td>filters_32_64_128_256_512_act_ReLU_drop_0.3_lr...</td>\n",
              "      <td>23.638181</td>\n",
              "      <td>True</td>\n",
              "      <td>0.3</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>[32, 64, 128, 256, 512]</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3zjvp08t</td>\n",
              "      <td>filters_32_32_32_32_32_act_GELU_drop_0.3_lr_0....</td>\n",
              "      <td>23.588206</td>\n",
              "      <td>True</td>\n",
              "      <td>0.3</td>\n",
              "      <td>True</td>\n",
              "      <td>64</td>\n",
              "      <td>7</td>\n",
              "      <td>[32, 32, 32, 32, 32]</td>\n",
              "      <td>GELU</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9xj83q16</td>\n",
              "      <td>filters_64_64_64_64_64_act_Mish_drop_0.3_lr_0....</td>\n",
              "      <td>22.138931</td>\n",
              "      <td>False</td>\n",
              "      <td>0.3</td>\n",
              "      <td>False</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>[64, 64, 64, 64, 64]</td>\n",
              "      <td>Mish</td>\n",
              "      <td>512</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ae7rkta1</td>\n",
              "      <td>filters_64_64_64_64_64_act_ReLU_drop_0.3_lr_0....</td>\n",
              "      <td>21.189405</td>\n",
              "      <td>False</td>\n",
              "      <td>0.3</td>\n",
              "      <td>False</td>\n",
              "      <td>64</td>\n",
              "      <td>5</td>\n",
              "      <td>[64, 64, 64, 64, 64]</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>85rvt8bv</td>\n",
              "      <td>filters_32_32_32_32_32_act_GELU_drop_0.3_lr_0....</td>\n",
              "      <td>20.289855</td>\n",
              "      <td>True</td>\n",
              "      <td>0.3</td>\n",
              "      <td>False</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>[32, 32, 32, 32, 32]</td>\n",
              "      <td>GELU</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nwjsp1rh</td>\n",
              "      <td>filters_128_64_32_16_8_act_SiLU_drop_0.2_lr_0....</td>\n",
              "      <td>19.740130</td>\n",
              "      <td>False</td>\n",
              "      <td>0.2</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>[128, 64, 32, 16, 8]</td>\n",
              "      <td>SiLU</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2grudf0s</td>\n",
              "      <td>filters_32_64_128_256_512_act_ReLU_drop_0.3_lr...</td>\n",
              "      <td>19.590205</td>\n",
              "      <td>True</td>\n",
              "      <td>0.3</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>[32, 64, 128, 256, 512]</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>128</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>d7lyctax</td>\n",
              "      <td>filters_32_32_32_32_32_act_SiLU_drop_0.3_lr_0....</td>\n",
              "      <td>18.490755</td>\n",
              "      <td>True</td>\n",
              "      <td>0.3</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>[32, 32, 32, 32, 32]</td>\n",
              "      <td>SiLU</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>aczycbfv</td>\n",
              "      <td>filters_32_32_32_32_32_act_ReLU_drop_0.2_lr_0....</td>\n",
              "      <td>17.391304</td>\n",
              "      <td>False</td>\n",
              "      <td>0.2</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>[32, 32, 32, 32, 32]</td>\n",
              "      <td>ReLU</td>\n",
              "      <td>256</td>\n",
              "      <td>0.0005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>rsglf1xw</td>\n",
              "      <td>filters_128_64_32_16_8_act_SiLU_drop_0.2_lr_0....</td>\n",
              "      <td>17.341329</td>\n",
              "      <td>False</td>\n",
              "      <td>0.2</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>[128, 64, 32, 16, 8]</td>\n",
              "      <td>SiLU</td>\n",
              "      <td>512</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a886b791-60a7-4d2c-8ec7-a3e2fe104792')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a886b791-60a7-4d2c-8ec7-a3e2fe104792 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a886b791-60a7-4d2c-8ec7-a3e2fe104792');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2aa7a73-c961-440b-88ec-71043715755d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2aa7a73-c961-440b-88ec-71043715755d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2aa7a73-c961-440b-88ec-71043715755d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"aczycbfv\",\n          \"d7lyctax\",\n          \"cb3pe6uw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"filters_32_32_32_32_32_act_GELU_drop_0.3_lr_0.001_bn_False\",\n          \"filters_32_64_128_256_512_act_GELU_drop_0.3_lr_0.0005_bn_False\",\n          \"filters_32_32_32_32_32_act_ReLU_drop_0.2_lr_0.0005_bn_True\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_val_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.2973496809510445,\n        \"min\": 17.341329335332333,\n        \"max\": 28.835582208895552,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          17.391304347826086,\n          18.490754622688655,\n          28.835582208895552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"augment\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dropout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04522670168666453,\n        \"min\": 0.2,\n        \"max\": 0.3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.2,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_norm\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 16,\n        \"max\": 64,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          16,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 3,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conv_filters\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"activation_fn\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ReLU\",\n          \"SiLU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dense_neurons\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 142,\n        \"min\": 128,\n        \"max\": 512,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          128,\n          256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00026111648393354676,\n        \"min\": 0.0005,\n        \"max\": 0.001,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.001,\n          0.0005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_best_model(model, train_loader, criterion, optimizer, device, epochs=10, checkpoint_path=None):\n",
        "    import os\n",
        "    from tqdm import tqdm\n",
        "    import wandb\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Create checkpoint path using wandb run ID\n",
        "    run_id = wandb.run.id if wandb.run else \"best_run\"\n",
        "    checkpoint_dir = \"checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    checkpoint_path = checkpoint_path or os.path.join(checkpoint_dir, f\"ckpt_{run_id}.pth\")\n",
        "\n",
        "    # Try loading from checkpoint\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            start_epoch = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "            print(f\"✅ Loaded checkpoint from '{checkpoint_path}', resuming at epoch {start_epoch}.\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"⚠️  Skipping checkpoint load due to mismatch:\\n{e}\")\n",
        "            start_epoch = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        print(f\"\\n📘 Epoch {epoch+1}/{epochs}:\")\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        avg_loss = total_loss / total\n",
        "\n",
        "        #wandb.log({\n",
        "        #   \"epoch\": epoch + 1,\n",
        "        #   \"train_loss\": avg_loss,\n",
        "        #   \"train_acc\": train_acc\n",
        "        #})\n",
        "\n",
        "        print(f\"✅ Train Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "\n",
        "def evaluate_best_model_on_test(best_config, train_loader, test_loader):\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"\\n🚀 Using device: {device}\")\n",
        "\n",
        "    # Build model from best config\n",
        "    model = CNN(\n",
        "        conv_filters=best_config['conv_filters'],\n",
        "        activation_fn=getattr(nn, best_config['activation_fn']),\n",
        "        dense_neurons=best_config['dense_neurons']\n",
        "    ).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=best_config['learning_rate'])\n",
        "\n",
        "    # Train model on full train set\n",
        "    train_best_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        #val_loader=None,  # No validation here since we're evaluating final model\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        epochs=best_config['num_epochs']\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_acc = validate_model(model, test_loader, device=device)\n",
        "    print(f\"\\nFinal Test Accuracy of Best Model: {test_acc:.2f}%\")\n",
        "    return model\n",
        "\n",
        "\n",
        "best_config = {\n",
        "    'conv_filters': [32, 64, 128, 256, 512],\n",
        "    'activation_fn': 'GELU',\n",
        "    'dropout': 0.3,\n",
        "    'batch_norm': False,\n",
        "    'batch_size': 16,\n",
        "    'num_epochs': 1,\n",
        "    'learning_rate': 0.0005,\n",
        "    'dense_neurons': 128,\n",
        "    'augment': True\n",
        "}\n",
        "\n",
        "model = evaluate_best_model_on_test(best_config, train_loader, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y4RpUywNeWy",
        "outputId": "c1e30bbb-1435-4622-de9d-b35bd59f0e91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Using device: cpu\n",
            "\n",
            "📘 Epoch 1/1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 1: 100%|██████████| 126/126 [1:02:04<00:00, 29.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 2.2841 | Train Acc: 12.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 32/32 [13:22<00:00, 25.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy of Best Model: 16.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions_grid(model, test_loader, class_names, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # Collect 30 samples from the test set\n",
        "    samples = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = outputs.max(1)\n",
        "\n",
        "            for img, true_label, pred_label in zip(images, labels, preds):\n",
        "                samples.append((img.cpu(), true_label.item(), pred_label.item()))\n",
        "                if len(samples) >= 30:\n",
        "                    break\n",
        "            if len(samples) >= 30:\n",
        "                break\n",
        "\n",
        "    # Plot 10x3 grid\n",
        "    fig, axes = plt.subplots(10, 3, figsize=(10, 25))\n",
        "    fig.suptitle(\"🧠 Predictions by Best CNN Model\", fontsize=16, weight='bold')\n",
        "\n",
        "    for idx, (img, true, pred) in enumerate(samples):\n",
        "        row, col = divmod(idx, 3)\n",
        "        ax = axes[row][col]\n",
        "\n",
        "        img = img.permute(1, 2, 0).numpy()\n",
        "        img = (img - img.min()) / (img.max() - img.min())  # Normalize for display\n",
        "\n",
        "        ax.imshow(img)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        color = 'green' if true == pred else 'red'\n",
        "        ax.set_title(f\"True: {class_names[true]}\\nPred: {class_names[pred]}\",\n",
        "                     fontsize=10, color=color)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "cXOZTq5sryiY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = test_loader.dataset.classes\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\n🚀 Using device: {device}\")\n",
        "\n",
        "show_predictions_grid(model, test_loader, class_names, device)"
      ],
      "metadata": {
        "id": "ZmGDkpOhK4cU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}